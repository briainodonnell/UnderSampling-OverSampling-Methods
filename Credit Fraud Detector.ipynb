{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit Fraud Detector\n",
    "\n",
    "### 1. Introduction\n",
    "This is a project I found on Kaggle to analyze whether anonymised credit card transations should be labelled as fraudulent or genuine. I undertook this project to get some experience in working with imbalanced datasets, applying the correct methodology to UnderSample / OverSample the dataset. I was working for a Fintech company aiming to build a credit scoring model.  For the Credit Scoring model, there are many more non-defaulting loans than defaulting loans. Similarly in this project, there are many more non-fraudulent transactions than fraudulent transactions.\n",
    "\n",
    "Kaggle Link: https://www.kaggle.com/mlg-ulb/creditcardfraud\n",
    "\n",
    "#### Context (from Kaggle description)\n",
    "It is important that credit card companies are able to recognize fraudulent credit card transactions so that customers are not charged for items that they did not purchase.\n",
    "\n",
    "#### Content (from Kaggle description)\n",
    "The datasets contains transactions made by credit cards in September 2013 by european cardholders. This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
    "\n",
    "It contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, ... V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References:\n",
    "- Machine Learning - Over-& Undersampling - Python/ Scikit/ Scikit-Imblearn by Coding-Maniac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Modules and Reading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# General Libraries\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "import matplotlib.patches as mpatches\n",
    "import time\n",
    "\n",
    "# Classifier Libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import collections\n",
    "\n",
    "# Other Libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Reading in the dataset\n",
    "modelling_df = pd.read_csv('C:/Users/briai/Documents/Jupyter/Python Projects/Credit Fraud Detector/creditcard.csv')\n",
    "modelling_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Understanding Our Data:\n",
    "As mentioned earlier, all features except for \"time\" and \"amount\" have already been scaled. Therefore we don't know anything about features V1 to V28 except for the fact that they have already been scaled. There are no null values and as expected, the majority of transactions are Non-Fraud, occuring 99.83% of the time and the remaining 0.17% are Fraudulent transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.919560e-15</td>\n",
       "      <td>5.688174e-16</td>\n",
       "      <td>-8.769071e-15</td>\n",
       "      <td>2.782312e-15</td>\n",
       "      <td>-1.552563e-15</td>\n",
       "      <td>2.010663e-15</td>\n",
       "      <td>-1.694249e-15</td>\n",
       "      <td>-1.927028e-16</td>\n",
       "      <td>-3.137024e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.537294e-16</td>\n",
       "      <td>7.959909e-16</td>\n",
       "      <td>5.367590e-16</td>\n",
       "      <td>4.458112e-15</td>\n",
       "      <td>1.453003e-15</td>\n",
       "      <td>1.699104e-15</td>\n",
       "      <td>-3.660161e-16</td>\n",
       "      <td>-1.206049e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.919560e-15  5.688174e-16 -8.769071e-15  2.782312e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552563e-15  2.010663e-15 -1.694249e-15 -1.927028e-16 -3.137024e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.537294e-16  7.959909e-16  5.367590e-16  4.458112e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   1.453003e-15  1.699104e-15 -3.660161e-16 -1.206049e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelling_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 null values\n"
     ]
    }
   ],
   "source": [
    "# Checking for any null values\n",
    "print(modelling_df.isnull().sum().max(), 'null values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Frauds 99.83 % of the dataset\n",
      "Frauds 0.17 % of the dataset\n"
     ]
    }
   ],
   "source": [
    "# Putting a figure on the level of skew in the target variable\n",
    "print('No Frauds', round(modelling_df['Class'].value_counts()[0]/len(modelling_df) * 100,2), '% of the dataset')\n",
    "print('Frauds', round(modelling_df['Class'].value_counts()[1]/len(modelling_df) * 100,2), '% of the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Class Distributions \\n (0: No Fraud || 1: Fraud)')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating a chart to show the distribution in the target class\n",
    "colors = [\"#0101DF\", \"#DF0101\"]\n",
    "\n",
    "sns.countplot('Class', data=modelling_df, palette=colors)\n",
    "plt.title('Class Distributions \\n (0: No Fraud || 1: Fraud)', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The source dataset is very imbalanced. This is a problem since we might get a lot of errors if we use this dataset as the base for our predictive models. This issue arises because our algorithm is likely to overfit because it will learn to \"assume\" that the majpority of transactions are non fraudulent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Preprocessing our Data\n",
    "First of all, we need to scale the columns \"Time\" and \"Amount\" just as the other columns are scaled. \n",
    "\n",
    "#### Sub-Sampling\n",
    "To solve the imbalanced data problem, we create a sub-sample of the dataset that has an equal number of Fraud and Non-Fraud cases. Our algorithm will therefore be better able to understand the underlying indicators as to whether a transaction is Fraud or not. We will set up our sub-samples to have a 50/50 ratio of Fraud and Non-Fraud cases. \n",
    "\n",
    "As mentioned, the original dataframe was highly imbalanced in favour of Non-Fraud cases. Using the original dataframe would cause several issues:\n",
    "- Overfitting: The model is will overfit the data and effectively assume that there are no frauds in the majority of cases.  \n",
    "- Incorrect Correlations: To evaluate the correlations between the input features and the target feature (Fraud vs Non-Fraud), we need to have an equal distribution in the target variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scaled_amount</th>\n",
       "      <th>scaled_time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.783274</td>\n",
       "      <td>-0.994983</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.269825</td>\n",
       "      <td>-0.994983</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.983721</td>\n",
       "      <td>-0.994972</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.418291</td>\n",
       "      <td>-0.994972</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.670579</td>\n",
       "      <td>-0.994960</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   scaled_amount  scaled_time        V1        V2        V3        V4  \\\n",
       "0       1.783274    -0.994983 -1.359807 -0.072781  2.536347  1.378155   \n",
       "1      -0.269825    -0.994983  1.191857  0.266151  0.166480  0.448154   \n",
       "2       4.983721    -0.994972 -1.358354 -1.340163  1.773209  0.379780   \n",
       "3       1.418291    -0.994972 -0.966272 -0.185226  1.792993 -0.863291   \n",
       "4       0.670579    -0.994960 -1.158233  0.877737  1.548718  0.403034   \n",
       "\n",
       "         V5        V6        V7        V8  ...       V20       V21       V22  \\\n",
       "0 -0.338321  0.462388  0.239599  0.098698  ...  0.251412 -0.018307  0.277838   \n",
       "1  0.060018 -0.082361 -0.078803  0.085102  ... -0.069083 -0.225775 -0.638672   \n",
       "2 -0.503198  1.800499  0.791461  0.247676  ...  0.524980  0.247998  0.771679   \n",
       "3 -0.010309  1.247203  0.237609  0.377436  ... -0.208038 -0.108300  0.005274   \n",
       "4 -0.407193  0.095921  0.592941 -0.270533  ...  0.408542 -0.009431  0.798278   \n",
       "\n",
       "        V23       V24       V25       V26       V27       V28  Class  \n",
       "0 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053      0  \n",
       "1  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724      0  \n",
       "2  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0  \n",
       "3 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458      0  \n",
       "4 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since most of our data has already been scaled we should scale the columns that are left to scale (Amount and Time)\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "# RobustScaler is less prone to outliers.\n",
    "rob_scaler = RobustScaler()\n",
    "# Fitting the robust scaler to the \"amount\" and \"time\" variables\n",
    "modelling_df['scaled_amount'] = rob_scaler.fit_transform(modelling_df['Amount'].values.reshape(-1,1))\n",
    "modelling_df['scaled_time'] = rob_scaler.fit_transform(modelling_df['Time'].values.reshape(-1,1))\n",
    "\n",
    "modelling_df.drop(['Time','Amount'], axis=1, inplace=True)\n",
    "scaled_amount = modelling_df['scaled_amount']\n",
    "scaled_time = modelling_df['scaled_time']\n",
    "modelling_df.drop(['scaled_amount', 'scaled_time'], axis=1, inplace=True)\n",
    "modelling_df.insert(0, 'scaled_amount', scaled_amount)\n",
    "modelling_df.insert(1, 'scaled_time', scaled_time)\n",
    "\n",
    "modelling_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the Data (Original DataFrame)\n",
    "To implement the Random UnderSampling technique, we must first divide the original dataframe into a training set and a testing set. We do this so that we can test the model on the **original testing set**, as opposed to a testing set created using Random UnderSampling \n",
    "\n",
    "Here we want to fit the model using the manipulated dataframe (UnderSampled or OverSampled) and proceed to test the model on the original testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [ 63421  63634  64329 ... 284804 284805 284806] Test: [    0     1     2 ... 94986 94987 94988]\n",
      "Train: [     0      1      2 ... 284804 284805 284806] Test: [ 63421  63634  64329 ... 189912 189913 189914]\n",
      "Train: [     0      1      2 ... 189912 189913 189914] Test: [152223 152295 153823 ... 284804 284805 284806]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "X = modelling_df.drop('Class', axis=1)\n",
    "y = modelling_df['Class']\n",
    "\n",
    "# Creating 3 folds with stratified classes in the target variable\n",
    "sss = StratifiedKFold(n_splits=3, random_state=None, shuffle=False)\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    print(\"Train:\", train_index, \"Test:\", test_index)\n",
    "    original_Xtrain, original_Xtest = X.iloc[train_index], X.iloc[test_index]\n",
    "    original_ytrain, original_ytest = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "# Turn into an array\n",
    "original_Xtrain = original_Xtrain.values\n",
    "original_Xtest = original_Xtest.values\n",
    "original_ytrain = original_ytrain.values\n",
    "original_ytest = original_ytest.values\n",
    "\n",
    "# Combining training datasets and testing datasets\n",
    "original_train = np.c_[original_Xtrain, original_ytrain]\n",
    "original_test = np.c_[original_Xtest, original_ytest]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking Size and Shape of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Training set:  66.67 %\n",
      "Size of Test set:  33.33 %\n",
      "------------------------------------------------------------------------------------------\n",
      "Default Training set - 0.17 %\n",
      "Default Test set - 0.17 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of Training set: \" , round(original_Xtrain.shape[0] / (original_Xtrain.shape[0] + original_Xtest.shape[0])*100, 2), \"%\")\n",
    "print(\"Size of Test set: \", round(original_Xtest.shape[0] / (original_Xtrain.shape[0] + original_Xtest.shape[0])*100, 2), \"%\")\n",
    "\n",
    "print('--' * 45)\n",
    "\n",
    "print('Default Training set -', round(len(original_ytrain[original_ytrain == 1]) / len(original_ytrain)*100, 2), \"%\")\n",
    "print('Default Test set -', round(len(original_ytest[original_ytest == 1]) / len(original_ytest)*100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Random Under-Sampling and Oversampling:\n",
    "The goal of these techniques are to produce a dataset that has an even distribution in the target variable. The former consists of removing data to achieve a balanced dataset and the latter consists of creating new synthetic data points to increase the frequency of the minority class. \n",
    "\n",
    "#### Implementing Random UnderSampling during Cross Validation:\n",
    "There is a common mistake made when carrying out these UnderSampling and OverSampling techniques. It is important not to undersample or oversample a dataset before cross-validating. The reason behind this is that we would be directly altering the validation set in advance of implementing cross-validation which would cause a \"data-leakage\" problem. Hence we conduct Random UnderSampling / SMOTE duirng the cross-validation process and not beforehand. Otherwise the results will be overfitting. \n",
    "\n",
    "#### Summary:\n",
    "- We carry out UnderSampling during Cross Validation and not beforehand \n",
    "- KNN and Logistic Regression have the best accuracy scores while SVC and Decision Trees have poor accuracy scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "\n",
      "accuracy: 95.41 %\n",
      "precision: 0.34 %\n",
      "recall: 95.41 %\n",
      "f1: 0.69 %\n",
      "AUC: 73.0 %\n",
      "------------------------------------------------------------------------------------------\n",
      "KNN\n",
      "\n",
      "accuracy: 92.68 %\n",
      "precision: 0.41 %\n",
      "recall: 92.68 %\n",
      "f1: 0.81 %\n",
      "AUC: 73.92 %\n",
      "------------------------------------------------------------------------------------------\n",
      "SVC\n",
      "\n",
      "accuracy: 11.45 %\n",
      "precision: 0.19 %\n",
      "recall: 96.94 %\n",
      "f1: 0.38 %\n",
      "AUC: 54.12 %\n",
      "------------------------------------------------------------------------------------------\n",
      "Trees\n",
      "\n",
      "accuracy: 13.54 %\n",
      "precision: 0.18 %\n",
      "recall: 91.75 %\n",
      "f1: 0.37 %\n",
      "AUC: 52.58 %\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Creating empty lists for each evaluation metric and for each model type\n",
    "undersample_accuracy_logreg = []\n",
    "undersample_precision_logreg = []\n",
    "undersample_recall_logreg = []\n",
    "undersample_f1_logreg = []\n",
    "undersample_auc_logreg = []\n",
    "undersample_accuracy_knn = []\n",
    "undersample_precision_knn = []\n",
    "undersample_recall_knn = []\n",
    "undersample_f1_knn = []\n",
    "undersample_auc_knn = []\n",
    "undersample_accuracy_svc = []\n",
    "undersample_precision_svc = []\n",
    "undersample_recall_svc = []\n",
    "undersample_f1_svc = []\n",
    "undersample_auc_svc = []\n",
    "undersample_accuracy_trees = []\n",
    "undersample_precision_trees = []\n",
    "undersample_recall_trees = []\n",
    "undersample_f1_trees = []\n",
    "undersample_auc_trees = []\n",
    "\n",
    "# Instantiating the parameters to be Grid Searched by each model\n",
    "log_reg_params = {\"penalty\": ['l1', 'l2'], 'C': [0.01, 0.1, 1, 10, 100]}\n",
    "knn_params = {\"n_neighbors\": list(range(2,5,1)), 'algorithm': ['auto', 'ball_tree', 'kd_tree']}\n",
    "svc_params = {'C': [0.5, 0.7, 0.9, 1.0], 'kernel': ['rbf','sigmoid']}  \n",
    "tree_params = {\"criterion\": [\"gini\", \"entropy\"], \n",
    "               \"max_depth\": list(range(2,6,1)),\n",
    "               \"min_samples_leaf\": list(range(1,7,1))}\n",
    "\n",
    "# Setting up the Grid Search Cross Validation\n",
    "rand_logreg = GridSearchCV(LogisticRegression(multi_class='ovr', solver='liblinear', max_iter=1000), log_reg_params, scoring=\"recall\")\n",
    "rand_knn = GridSearchCV(KNeighborsClassifier(), knn_params, scoring=\"recall\")\n",
    "rand_svc = GridSearchCV(SVC(), svc_params, scoring=\"recall\")\n",
    "rand_tree = GridSearchCV(DecisionTreeClassifier(), tree_params, scoring=\"recall\")\n",
    "\n",
    "# Implementing Random UnderSampling NearMiss Technique (Cross Validating the right way)\n",
    "for train_index, valid_index in sss.split(original_Xtrain, original_ytrain):\n",
    "\n",
    "    # Fitting best model for Logistic Regression\n",
    "    undersample_pipeline_logreg = imbalanced_make_pipeline(NearMiss(sampling_strategy='majority'), rand_logreg) # Undersampling happens during Cross Validation not before\n",
    "    undersample_model_logreg = undersample_pipeline_logreg.fit(original_Xtrain[train_index], original_ytrain[train_index])\n",
    "    undersample_prediction_logreg = undersample_model_logreg.predict(original_Xtrain[valid_index])\n",
    "\n",
    "    # Fitting best model for KNN\n",
    "    undersample_pipeline_knn = imbalanced_make_pipeline(NearMiss(sampling_strategy='majority'), rand_knn) # Undersampling happens during Cross Validation not before\n",
    "    undersample_model_knn = undersample_pipeline_knn.fit(original_Xtrain[train_index], original_ytrain[train_index])\n",
    "    undersample_prediction_knn = undersample_model_knn.predict(original_Xtrain[valid_index])\n",
    "\n",
    "    # Fitting best model for SVC\n",
    "    undersample_pipeline_svc = imbalanced_make_pipeline(NearMiss(sampling_strategy='majority'), svc_uds) # Undersampling happens during Cross Validation not before\n",
    "    undersample_model_svc = undersample_pipeline_svc.fit(original_Xtrain[train_index], original_ytrain[train_index])\n",
    "    undersample_prediction_svc = undersample_model_svc.predict(original_Xtrain[valid_index])\n",
    "\n",
    "    # Fitting best model for Trees\n",
    "    undersample_pipeline_trees = imbalanced_make_pipeline(NearMiss(sampling_strategy='majority'), tree_clf_uds) # Undersampling happens during Cross Validation not before\n",
    "    undersample_model_trees = undersample_pipeline_trees.fit(original_Xtrain[train_index], original_ytrain[train_index])\n",
    "    undersample_prediction_trees = undersample_model_trees.predict(original_Xtrain[valid_index])\n",
    "          \n",
    "    #### Calculating Performance Metrics for each Model\n",
    "    # Performance Metrics for Logreg model\n",
    "    undersample_accuracy_logreg.append(undersample_pipeline_logreg.score(original_Xtrain[valid_index], original_ytrain[valid_index]))\n",
    "    undersample_precision_logreg.append(precision_score(original_ytrain[valid_index], undersample_prediction_logreg))\n",
    "    undersample_recall_logreg.append(recall_score(original_ytrain[valid_index], undersample_prediction_logreg))\n",
    "    undersample_f1_logreg.append(f1_score(original_ytrain[valid_index], undersample_prediction_logreg))\n",
    "    undersample_auc_logreg.append(roc_auc_score(original_ytrain[valid_index], undersample_prediction_logreg))\n",
    "    \n",
    "    # Performance Metrics for KNN model\n",
    "    undersample_accuracy_knn.append(undersample_pipeline_knn.score(original_Xtrain[valid_index], original_ytrain[valid_index]))\n",
    "    undersample_precision_knn.append(precision_score(original_ytrain[valid_index], undersample_prediction_knn))\n",
    "    undersample_recall_knn.append(recall_score(original_ytrain[valid_index], undersample_prediction_knn))\n",
    "    undersample_f1_knn.append(f1_score(original_ytrain[valid_index], undersample_prediction_knn))\n",
    "    undersample_auc_knn.append(roc_auc_score(original_ytrain[valid_index], undersample_prediction_knn))\n",
    "\n",
    "    # Performance Metrics for SVC model\n",
    "    undersample_accuracy_svc.append(undersample_pipeline_svc.score(original_Xtrain[valid_index], original_ytrain[valid_index]))\n",
    "    undersample_precision_svc.append(precision_score(original_ytrain[valid_index], undersample_prediction_svc))\n",
    "    undersample_recall_svc.append(recall_score(original_ytrain[valid_index], undersample_prediction_svc))\n",
    "    undersample_f1_svc.append(f1_score(original_ytrain[valid_index], undersample_prediction_svc))\n",
    "    undersample_auc_svc.append(roc_auc_score(original_ytrain[valid_index], undersample_prediction_svc))\n",
    "\n",
    "    # Performance Metrics for Trees model\n",
    "    undersample_accuracy_trees.append(undersample_pipeline_trees.score(original_Xtrain[valid_index], original_ytrain[valid_index]))\n",
    "    undersample_precision_trees.append(precision_score(original_ytrain[valid_index], undersample_prediction_trees))\n",
    "    undersample_recall_trees.append(recall_score(original_ytrain[valid_index], undersample_prediction_trees))\n",
    "    undersample_f1_trees.append(f1_score(original_ytrain[valid_index], undersample_prediction_trees))\n",
    "    undersample_auc_trees.append(roc_auc_score(original_ytrain[valid_index], undersample_prediction_trees))\n",
    "\n",
    "print('Logistic Regression')\n",
    "print('')\n",
    "print(\"accuracy: {}\".format( round(np.mean(undersample_accuracy_logreg)*100, 2)), \"%\" )\n",
    "print(\"precision: {}\".format( round(np.mean(undersample_precision_logreg)*100, 2)), \"%\" )\n",
    "print(\"recall: {}\".format( round(np.mean(undersample_recall_logreg)*100, 2)), \"%\" )\n",
    "print(\"f1: {}\".format( round(np.mean(undersample_f1_logreg)*100, 2)), \"%\" )\n",
    "print(\"AUC: {}\".format( round(np.mean(undersample_auc_logreg)*100, 2)), \"%\" )\n",
    "print('--' * 45)\n",
    "print('KNN')\n",
    "print('')\n",
    "print(\"accuracy: {}\".format( round(np.mean(undersample_accuracy_knn)*100, 2)), \"%\" )\n",
    "print(\"precision: {}\".format( round(np.mean(undersample_precision_knn)*100, 2)), \"%\" )\n",
    "print(\"recall: {}\".format( round(np.mean(undersample_recall_knn)*100, 2)), \"%\" )\n",
    "print(\"f1: {}\".format( round(np.mean(undersample_f1_knn)*100, 2)), \"%\" )\n",
    "print(\"AUC: {}\".format( round(np.mean(undersample_auc_knn)*100, 2)), \"%\" )\n",
    "print('--' * 45)\n",
    "print('SVC')\n",
    "print('')\n",
    "print(\"accuracy: {}\".format( round(np.mean(undersample_accuracy_svc)*100, 2)), \"%\" )\n",
    "print(\"precision: {}\".format( round(np.mean(undersample_precision_svc)*100, 2)), \"%\" )\n",
    "print(\"recall: {}\".format( round(np.mean(undersample_recall_svc)*100, 2)), \"%\" )\n",
    "print(\"f1: {}\".format( round(np.mean(undersample_f1_svc)*100, 2)), \"%\" )\n",
    "print(\"AUC: {}\".format( round(np.mean(undersample_auc_svc)*100, 2)), \"%\" )\n",
    "print('--' * 45)\n",
    "print('Trees')\n",
    "print('')\n",
    "print(\"accuracy: {}\".format( round(np.mean(undersample_accuracy_trees)*100, 2)), \"%\" )\n",
    "print(\"precision: {}\".format( round(np.mean(undersample_precision_trees)*100, 2)), \"%\" )\n",
    "print(\"recall: {}\".format( round(np.mean(undersample_recall_trees)*100, 2)), \"%\" )\n",
    "print(\"f1: {}\".format( round(np.mean(undersample_f1_trees)*100, 2)), \"%\" )\n",
    "print(\"AUC: {}\".format( round(np.mean(undersample_auc_trees)*100, 2)), \"%\" )\n",
    "print('--' * 45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. SMOTE Analysis\n",
    "\n",
    "Now we will carry out a similar procedure known as SMOTE (Synthetic Minority Over-sampling Technique). This is different to Random UnderSampling in that it creates new synthetic data points to ensure there is an equal balance between the two classes in the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oversampling during cross validation\n",
    "\n",
    "Similar to the problem we encountered before, we need to carry out the OverSampling method during Cross Validation as opposed to beforehand. We do this to avoid the \"Data Leakage\" problem descrived earlier in this notebok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "\n",
      "accuracy: 87.18 %\n",
      "precision: 4.95 %\n",
      "recall: 87.18 %\n",
      "f1: 9.12 %\n",
      "AUC: 86.13 %\n",
      "------------------------------------------------------------------------------------------\n",
      "KNN\n",
      "\n",
      "accuracy: 73.78 %\n",
      "precision: 46.67 %\n",
      "recall: 73.78 %\n",
      "f1: 55.79 %\n",
      "AUC: 86.8 %\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Creating empty lists for each evaluation metric and for each model type\n",
    "oversample_accuracy_logreg = []\n",
    "oversample_precision_logreg = []\n",
    "oversample_recall_logreg = []\n",
    "oversample_f1_logreg = []\n",
    "oversample_auc_logreg = []\n",
    "oversample_accuracy_knn = []\n",
    "oversample_precision_knn = []\n",
    "oversample_recall_knn = []\n",
    "oversample_f1_knn = []\n",
    "oversample_auc_knn = []\n",
    "\n",
    "# Instantiating the parameters to be Grid Searched by each model\n",
    "log_reg_params = {\"penalty\": ['l1', 'l2'], 'C': [0.01, 0.1, 1, 10, 100]}\n",
    "knn_params = {\"n_neighbors\": list(range(2,5,1)), 'algorithm': ['auto', 'ball_tree', 'kd_tree']}\n",
    "\n",
    "# Setting up the Grid Search Cross Validation\n",
    "rand_logreg = GridSearchCV(LogisticRegression(multi_class='ovr', solver='liblinear', max_iter=1000), log_reg_params, scoring=\"recall\")\n",
    "rand_knn = GridSearchCV(KNeighborsClassifier(), knn_params, scoring=\"recall\")\n",
    "\n",
    "# Implementing OverSampling SMOTE Technique (Cross Validating the right way)\n",
    "for train_index, valid_index in sss.split(original_Xtrain, original_ytrain):\n",
    "    \n",
    "    #### Fitting each Model\n",
    "    # Fitting best model for Logistic Regression\n",
    "    oversample_pipeline_logreg = imbalanced_make_pipeline(SMOTE(sampling_strategy='minority'), rand_logreg) # SMOTE happens during Cross Validation not before\n",
    "    oversample_model_logreg = oversample_pipeline_logreg.fit(original_Xtrain[train_index], original_ytrain[train_index]) \n",
    "    oversample_prediction_logreg = oversample_model_logreg.predict(original_Xtrain[valid_index])\n",
    "    \n",
    "    # Fitting best model for KNN\n",
    "    oversample_pipeline_knn = imbalanced_make_pipeline(SMOTE(sampling_strategy='minority'), rand_knn) # SMOTE happens during Cross Validation not before\n",
    "    oversample_model_knn = oversample_pipeline_knn.fit(original_Xtrain[train_index], original_ytrain[train_index]) \n",
    "    oversample_prediction_knn = oversample_model_knn.predict(original_Xtrain[valid_index])\n",
    "    \n",
    "    #### Calculating Performance Metrics for each Model\n",
    "    # Performance Metrics for Logreg model\n",
    "    oversample_accuracy_logreg.append(oversample_pipeline_logreg.score(original_Xtrain[valid_index], original_ytrain[valid_index]))\n",
    "    oversample_precision_logreg.append(precision_score(original_ytrain[valid_index], oversample_prediction_logreg))\n",
    "    oversample_recall_logreg.append(recall_score(original_ytrain[valid_index], oversample_prediction_logreg))\n",
    "    oversample_f1_logreg.append(f1_score(original_ytrain[valid_index], oversample_prediction_logreg))\n",
    "    oversample_auc_logreg.append(roc_auc_score(original_ytrain[valid_index], oversample_prediction_logreg))\n",
    "\n",
    "    # Performance Metrics for KNN model\n",
    "    oversample_accuracy_knn.append(oversample_pipeline_knn.score(original_Xtrain[valid_index], original_ytrain[valid_index]))\n",
    "    oversample_precision_knn.append(precision_score(original_ytrain[valid_index], oversample_prediction_knn))\n",
    "    oversample_recall_knn.append(recall_score(original_ytrain[valid_index], oversample_prediction_knn))\n",
    "    oversample_f1_knn.append(f1_score(original_ytrain[valid_index], oversample_prediction_knn))\n",
    "    oversample_auc_knn.append(roc_auc_score(original_ytrain[valid_index], oversample_prediction_knn))\n",
    "    \n",
    "print('Logistic Regression')\n",
    "print('')\n",
    "print(\"accuracy: {}\".format( round(np.mean(oversample_accuracy_logreg)*100, 2)), \"%\" )\n",
    "print(\"precision: {}\".format( round(np.mean(oversample_precision_logreg)*100, 2)), \"%\" )\n",
    "print(\"recall: {}\".format( round(np.mean(oversample_recall_logreg)*100, 2)), \"%\" )\n",
    "print(\"f1: {}\".format( round(np.mean(oversample_f1_logreg)*100, 2)), \"%\" )\n",
    "print(\"AUC: {}\".format( round(np.mean(oversample_auc_logreg)*100, 2)), \"%\" )\n",
    "print('--' * 45)\n",
    "print('KNN')\n",
    "print('')\n",
    "print(\"accuracy: {}\".format( round(np.mean(oversample_accuracy_knn)*100, 2)), \"%\" )\n",
    "print(\"precision: {}\".format( round(np.mean(oversample_precision_knn)*100, 2)), \"%\" )\n",
    "print(\"recall: {}\".format( round(np.mean(oversample_recall_knn)*100, 2)), \"%\" )\n",
    "print(\"f1: {}\".format( round(np.mean(oversample_f1_knn)*100, 2)), \"%\" )\n",
    "print(\"AUC: {}\".format( round(np.mean(oversample_auc_knn)*100, 2)), \"%\" )\n",
    "print('--' * 45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test Data with Logistic Regression:\n",
    "Now we apply our classification models to the test dataset created earlier in the analysis. \n",
    "\n",
    "#### Summary:\n",
    "- Classification Models: The models that performed the best were logistic regression and KNN so we apply these to the test data.\n",
    "- We apply the models that were trained the \"right\" way (OverSampling / UnderSampling during CV) and the  \"wrong\" way (OverSampling / UnderSampling before CV).\n",
    "- The models that were trained the \"right\" way perform much better when faced with the unseen test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1584x864 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Logistic Regression fitted using SMOTE technique\n",
    "y_pred_logreg_sm = oversample_model_logreg.predict(original_Xtest)\n",
    "# KNN fitted using SMOTE technique\n",
    "y_pred_knn_sm = oversample_model_knn.predict(original_Xtest)\n",
    "\n",
    "# Other models fitted with UnderSampling\n",
    "y_pred_logreg_uds = undersample_model_logreg.predict(original_Xtest)\n",
    "y_pred_knn_uds = undersample_model_knn.predict(original_Xtest)\n",
    "\n",
    "logreg_sm_cf = confusion_matrix(original_ytest, y_pred_logreg_sm)\n",
    "knn_sm_cf = confusion_matrix(original_ytest, y_pred_knn_sm)\n",
    "logreg_uds_cf = confusion_matrix(original_ytest, y_pred_logreg_uds)\n",
    "knn_uds_cf = confusion_matrix(original_ytest, y_pred_knn_uds)\n",
    "\n",
    "fig, ax = plt.subplots(2, 2,figsize=(22,12))\n",
    "\n",
    "sns.heatmap(logreg_sm_cf, ax=ax[0][0], annot=True, cmap=plt.cm.copper)\n",
    "ax[0, 0].set_title(\"Logistic Regression SMOTE \\n Confusion Matrix\", fontsize=14)\n",
    "ax[0, 0].set_xticklabels(['', ''], fontsize=14, rotation=90)\n",
    "ax[0, 0].set_yticklabels(['', ''], fontsize=14, rotation=360)\n",
    "\n",
    "sns.heatmap(knn_sm_cf, ax=ax[0][1], annot=True, cmap=plt.cm.copper)\n",
    "ax[0][1].set_title(\"KNN SMOTE \\n Confusion Matrix\", fontsize=14)\n",
    "ax[0][1].set_xticklabels(['', ''], fontsize=14, rotation=90)\n",
    "ax[0][1].set_yticklabels(['', ''], fontsize=14, rotation=360)\n",
    "\n",
    "sns.heatmap(logreg_uds_cf, ax=ax[1][0], annot=True, cmap=plt.cm.copper)\n",
    "ax[1][0].set_title(\"Logreg UnderSample \\n Confusion Matrix\", fontsize=14)\n",
    "ax[1][0].set_xticklabels(['', ''], fontsize=14, rotation=90)\n",
    "ax[1][0].set_yticklabels(['', ''], fontsize=14, rotation=360)\n",
    "\n",
    "sns.heatmap(knn_uds_cf, ax=ax[1][1], annot=True, cmap=plt.cm.copper)\n",
    "ax[1][1].set_title(\"KNN UnderSample \\n Confusion Matrix\", fontsize=14)\n",
    "ax[1][1].set_xticklabels(['', ''], fontsize=14, rotation=90)\n",
    "ax[1][1].set_yticklabels(['', ''], fontsize=14, rotation=360)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     94771\n",
      "           1       0.09      0.80      0.17       164\n",
      "\n",
      "    accuracy                           0.99     94935\n",
      "   macro avg       0.55      0.89      0.58     94935\n",
      "weighted avg       1.00      0.99      0.99     94935\n",
      "\n",
      "KNears Neighbors:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     94771\n",
      "           1       0.36      0.80      0.49       164\n",
      "\n",
      "    accuracy                           1.00     94935\n",
      "   macro avg       0.68      0.90      0.75     94935\n",
      "weighted avg       1.00      1.00      1.00     94935\n",
      "\n",
      "Support Vector Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.62      0.77     94771\n",
      "           1       0.00      0.96      0.01       164\n",
      "\n",
      "    accuracy                           0.62     94935\n",
      "   macro avg       0.50      0.79      0.39     94935\n",
      "weighted avg       1.00      0.62      0.77     94935\n",
      "\n",
      "Support Vector Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.77      0.87     94771\n",
      "           1       0.01      0.93      0.01       164\n",
      "\n",
      "    accuracy                           0.77     94935\n",
      "   macro avg       0.50      0.85      0.44     94935\n",
      "weighted avg       1.00      0.77      0.87     94935\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print('Logistic Regression:')\n",
    "print(classification_report(original_ytest, y_pred_logreg_sm))\n",
    "\n",
    "print('KNears Neighbors:')\n",
    "print(classification_report(original_ytest, y_pred_knn_sm))\n",
    "\n",
    "print('Support Vector Classifier:')\n",
    "print(classification_report(original_ytest, y_pred_logreg_uds))\n",
    "\n",
    "print('Support Vector Classifier:')\n",
    "print(classification_report(original_ytest, y_pred_knn_uds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Technique</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logreg: UnderSampling</td>\n",
       "      <td>0.623427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logreg - OverSampling</td>\n",
       "      <td>0.986317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN - UnderSampling</td>\n",
       "      <td>0.765713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN - OverSampling</td>\n",
       "      <td>0.997177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Technique     Score\n",
       "0  Logreg: UnderSampling  0.623427\n",
       "1  Logreg - OverSampling  0.986317\n",
       "2    KNN - UnderSampling  0.765713\n",
       "3     KNN - OverSampling  0.997177"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final Score in the test set of Logistic Regression and KNN\n",
    "\n",
    "# Logistic Regression with Under-Sampling\n",
    "y_pred_logreg_uds = undersample_model_logreg.predict(original_Xtest)\n",
    "undersample_score_logreg = accuracy_score(original_ytest, y_pred_logreg_uds)\n",
    "# Logistic Regression with SMOTE Technique \n",
    "y_pred_logreg_sm = oversample_model_logreg.predict(original_Xtest)\n",
    "oversample_score_logreg = accuracy_score(original_ytest, y_pred_logreg_sm)\n",
    "\n",
    "# KNN with Under-Sampling\n",
    "y_pred_knn_uds = undersample_model_knn.predict(original_Xtest)\n",
    "undersample_score_knn = accuracy_score(original_ytest, y_pred_knn_uds)\n",
    "# KNN with SMOTE Technique \n",
    "y_pred_knn_sm = oversample_model_knn.predict(original_Xtest)\n",
    "oversample_score_knn = accuracy_score(original_ytest, y_pred_knn_sm)\n",
    "\n",
    "# Creating the results dataframe\n",
    "results_data = {'Technique': ['Logreg: UnderSampling', 'Logreg - OverSampling', 'KNN - UnderSampling', 'KNN - OverSampling'], \n",
    "                'Score': [undersample_score_logreg, oversample_score_logreg, undersample_score_knn, oversample_score_knn]}\n",
    "results_df = pd.DataFrame(data=results_data)\n",
    "\n",
    "score = results_df['Score']\n",
    "results_df.drop('Score', axis=1, inplace=True)\n",
    "results_df.insert(1, 'Score', score)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "In this notebook we have implemented Random UnderSampling and SMOTE OverSampling with the correct Cross Validation methodology. By manipulating the datasets **during** cross validation and not beforehand, we avoid a Data Leakage problem and ensure the models are trained correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
